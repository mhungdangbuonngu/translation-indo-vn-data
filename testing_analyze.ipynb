{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import re \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn=psycopg2.connect('postgresql://public_owner:7CBm0fdOPkgz@ep-sweet-field-a1urmrzw.ap-southeast-1.aws.neon.tech/public?sslmode=require')\n",
    "query=\"SELECT * FROM indonesian_vietnamese_words\"\n",
    "chunks = pd.read_sql(query, conn, chunksize=1000)  # Adjust chunksize based on memory\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "  # replace with your file path\n",
    "indonesian_texts = df['Indonesian']\n",
    "vietnamese_texts = df['Vietnamese']\n",
    "\n",
    "# Basic statistics\n",
    "df['indo_word_count'] = indonesian_texts.apply(lambda x: len(x.split()))\n",
    "df['viet_word_count'] = vietnamese_texts.apply(lambda x: len(x.split()))\n",
    "df['indo_char_count'] = indonesian_texts.apply(len)\n",
    "df['viet_char_count'] = vietnamese_texts.apply(len)\n",
    "\n",
    "# Token statistics summary\n",
    "word_stats = df[['indo_word_count', 'viet_word_count']].describe()\n",
    "char_stats = df[['indo_char_count', 'viet_char_count']].describe()\n",
    "\n",
    "# Common words using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=10, stop_words='english')\n",
    "indo_word_freq = vectorizer.fit_transform(indonesian_texts).toarray().sum(axis=0)\n",
    "viet_word_freq = vectorizer.fit_transform(vietnamese_texts).toarray().sum(axis=0)\n",
    "indo_common_words = dict(zip(vectorizer.get_feature_names_out(), indo_word_freq))\n",
    "viet_common_words = dict(zip(vectorizer.get_feature_names_out(), viet_word_freq))\n",
    "\n",
    "# Sentence Pair Similarity using BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "def bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.pooler_output.detach().numpy()\n",
    "\n",
    "ind_embeddings = np.vstack([bert_embedding(text) for text in indonesian_texts])\n",
    "viet_embeddings = np.vstack([bert_embedding(text) for text in vietnamese_texts])\n",
    "similarities = cosine_similarity(ind_embeddings, viet_embeddings).diagonal()\n",
    "\n",
    "# Summary of similarities\n",
    "similarity_stats = {\n",
    "    'mean_similarity': np.mean(similarities),\n",
    "    'min_similarity': np.min(similarities),\n",
    "    'max_similarity': np.max(similarities)\n",
    "}\n",
    "\n",
    "print(\"Word Count Statistics:\", word_stats)\n",
    "print(\"Character Count Statistics:\", char_stats)\n",
    "print(\"Top Indonesian Words:\", indo_common_words)\n",
    "print(\"Top Vietnamese Words:\", viet_common_words)\n",
    "print(\"Translation Similarity Statistics:\", similarity_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load your dataset (replace with actual dataset file path\n",
    "\n",
    "# Calculate word lengths for each text in both languages\n",
    "df['indo_word_count'] = df['Indonesian'].apply(lambda x: len(x.split()))\n",
    "df['viet_word_count'] = df['Vietnamese'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot histogram of word count frequency\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['indo_word_count'], bins=range(1, max(df['indo_word_count']) + 2), alpha=0.5, label=\"Indonesian\")\n",
    "plt.hist(df['viet_word_count'], bins=range(1, max(df['viet_word_count']) + 2), alpha=0.5, label=\"Vietnamese\")\n",
    "plt.title(\"Word Count Frequency Histogram\")\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "# Find top 10 words for each language\n",
    "vectorizer_indo = CountVectorizer(max_features=10, stop_words=None)\n",
    "indo_word_freq = vectorizer_indo.fit_transform(data['Indonesian']).toarray().sum(axis=0)\n",
    "indo_common_words = dict(zip(vectorizer_indo.get_feature_names_out(), indo_word_freq))\n",
    "\n",
    "vectorizer_viet = CountVectorizer(max_features=10, stop_words=None)\n",
    "viet_word_freq = vectorizer_viet.fit_transform(data['Vietnamese']).toarray().sum(axis=0)\n",
    "viet_common_words = dict(zip(vectorizer_viet.get_feature_names_out(), viet_word_freq))\n",
    "\n",
    "# Plot top 10 words for Indonesian\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(indo_common_words.keys(), indo_common_words.values(), color='skyblue')\n",
    "plt.title(\"Top 10 Most Frequent Words in Indonesian\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Plot top 10 words for Vietnamese\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(viet_common_words.keys(), viet_common_words.values(), color='lightcoral')\n",
    "plt.title(\"Top 10 Most Frequent Words in Vietnamese\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
